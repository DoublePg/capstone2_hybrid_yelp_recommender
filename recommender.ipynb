{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommender system:**<br>\n",
    "* Module 1 - simple recommender:<br>\n",
    "build keyword search-based restaurant recommender module to filter by keyword. Keywords could include, for instance, location-based information (zip code, longitude, latitude)  and restaurant feature-based information (cuisine, style). \n",
    "The restaurant inventory will be filtered by keywords first, then ranked by its average rating or weighted smart rating taking into consideration the popularity (depending on user’s choice). The top-k restaurants from the list will be returned as the top-k recommendations.<br>\n",
    "* Module 2 - content filtering recommender:<br>\n",
    "With user ID and restaurant’s metadata, build a content based filtering recommender module that recommends restaurants that are similar to user’s preference inferred from user’s past ratings. More specifically, pairwise similarity scores will be computed for restaurants based on their vectorized feature representation extracted using CountVectorizer or TfidfVectorizer and recommend restaurants based on rankings of the weighted similarity score (e.g. cosine similarity). The important restaurant metadata to consider include categories, attributes, location.<br>\n",
    "* Module 3 - collaborative filtering recommender:<br>\n",
    "With user_id x restaurant_id rating matrix, build a collaborative filtering recommender module. Remember that the dataset has a total of 1,518,169 users, 188,593 businesses and 5,996,995 reviews. In terms of the user_id x business_id matrix, the matrix is very sparse (0.003% non-empty). Therefore, matrix factorization using ALS (alternative least square) will be used to complete the matrix and generate recommendations.<br>\n",
    "* Metrics chosen for evaluating and optimizing the ‘goodness’ of the algorithms:<br>\n",
    "a) measure prediction accuracy: RMSE(root mean squared error)\n",
    "b) measure ranking effectiveness: \n",
    "MAP (mean average precision)\n",
    "NDCG(Normalized Discounted Cumulative Gain)<br>\n",
    "* Integration - combine the above modules to build a hybrid recommendation engine:<br>\n",
    "To combine the above modules, a few simple interactive questions will be added:<br>\n",
    "a) “Want customized recommendations based on your user history by providing your user ID?”  If no, activate the simple recommender module to provide base-case recommendations using location information and/or optional keywords<br>\n",
    "b) If yes, prompt to ask follow up question: “do you want to try something new based on people like you?” If yes, activate the collaborative filtering module to recommend new restaurants based on similar peers; otherwise, use content filter module to recommend similar restaurants. <br>\n",
    "* Other improvements:<br>\n",
    "Optimize restaurant ranking by weighting the average rating based on total number of ratings (popularity), weighting the individual rating according to their recency, etc. With a quick interactive question: “want smart rating instead?” The alternative restaurant ranking method based on the above weighted scores will be activated and used instead of the simple average rating.<br>\n",
    "* Potential caveats - cold start problem:<br>\n",
    "a) new restaurant → content-based recommendation module will be able to use the features (metadata) of the new restaurant and include it when generating recommendations.<br>\n",
    "b) new user → will be treated as if the user ID is not available (both has no user history) and similar recommender module will be used to recommend restaurants based on location, keywords, popularity, etc. \n",
    "\n",
    "**Note:**<br> \n",
    "Only a subset of Yelp restaurants from a few selected states are available in this dataset. Among them, only Arizona, Nevada, Ohio, North Carolina and Pennsylvania have a rich catalog of over 5000 restaurants. \n",
    "\n",
    "Only the top two states, Arizona and Nevada have over 10000 restaurants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import string\n",
    "\n",
    "business = pd.read_csv('business_clean.csv')  # contains business data including location data, attributes and categories\n",
    "#user = pd.read_csv('user_clean.csv') # contains users data including the user's friend mapping and all the metadata associated with the user\n",
    "review = pd.read_csv('review_clean.csv') # contains full review text data including the user_id that wrote the review and the business_id the review is written for\n",
    "#tip = pd.read_csv('tip_clean.csv') # tips written by a user on a business, tips are shorter than reviews and tend to convey quick suggestions\n",
    "#checkin = pd.read_csv('checkin_clean.csv') # checkins on a business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Calculate Geodesic distance between two points on the globe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate geodesic distances between two points on a globe, see https://janakiev.com/blog/gps-points-distance-python/ for more resource\n",
    "# alternatively, one can use geopy.distance from geopy package to calculate either geodesic or great circle distance, https://github.com/geopy/geopy/blob/master/geopy/distance.py\n",
    "\n",
    "def great_circle_mile(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Compute geodesic distances (great-circle distance) of two points given their coordinates. \n",
    "    The function returns the distance in miles. \n",
    "    Note: 1. Calculation uses the earth's mean radius of 6371.009 km, \n",
    "    2. The central subtended angle is calculated by formula: \n",
    "    alpha = cos-1*[sin(lat1)*sin(lat2)+ cos(lat1)*cos(lat2)*cos(lon1-lon2)]\n",
    "    \"\"\"\n",
    "    \n",
    "    from math import sin, cos, acos, radians\n",
    "    \n",
    "    lat1, lon1, lat2, lon2 = radians(lat1), radians(lon1), radians(lat2), radians(lon2) # convert degrees to radians\n",
    "    earth_radius = 6371.009  # use earth's mean radius in kilometers\n",
    "    alpha = acos(sin(lat1)*sin(lat2) + cos(lat1)*cos(lat2)*cos(lon1-lon2)) # alpha is in radians\n",
    "    dis_km = alpha * earth_radius\n",
    "    dis_mile = dis_km * 0.621371   # convert kilometer to mile\n",
    "    \n",
    "    return dis_mile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos1 = (51.5073219, -0.1276474) # London\n",
    "pos2 = (52.5170365, 13.3888599) # Berlin\n",
    "pos3 = (-33.8548157,151.2164539) # Sydney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9 µs ± 160 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# great_circle distance\n",
    "distance_12 = great_circle_mile(pos1[0], pos1[1], pos2[0], pos2[1])\n",
    "distance_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230 µs ± 16 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# geodesic distance\n",
    "distance2_12 = distance(pos1, pos2).miles\n",
    "distance2_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolute error: -1.8326838373754981 2.892945931140275\n",
      "percent error: -0.0031598293601707256 0.0002740520023695907\n"
     ]
    }
   ],
   "source": [
    "distance_12 = great_circle_mile(pos1[0], pos1[1], pos2[0], pos2[1])\n",
    "distance2_12 = distance(pos1, pos2).miles\n",
    "error_12 = (distance_12 - distance2_12)/distance2_12\n",
    "\n",
    "distance_13 = great_circle_mile(pos1[0], pos1[1], pos3[0], pos3[1])\n",
    "distance2_13 = distance(pos1, pos3).miles\n",
    "error_13 = (distance_13 - distance2_13)/distance2_13\n",
    "\n",
    "# print errors, 1-2 is distance between London and Berlin, 1-3 is distance between London and Sydney\n",
    "print(\"absolute error:\", (distance_12-distance2_12), (distance_13-distance2_13)) \n",
    "print(\"percent error:\", error_12, error_13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick summary: \n",
    "Great-circle distance is reasonably accurate when compared with the geodesic distance calculated from an ellipsoidal model of the earth. Given that calculating great-circle distance is at least 100 times faster on average, great-circle distance will be used in this project when calculating geodistance on map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Adjusted rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, a single metric is introduced as a substitute of the original average restaurant rating ('stars' column of the business dataframe). Ideally, the new metric should take into consideration: <br>\n",
    "1) average rating of the restaurant (indicates the goodness of the restaurant, but does not consider popularity) <br>\n",
    "2) # of ratings by users (indicates popularity, but does not imply the goodness of the restaurant) <br>\n",
    "3) age of the rating (indicates the relevance of the rating, as outdated ratings might fail to indicate the actual quality)<br>\n",
    "\n",
    "The proposed new score is: \n",
    "$$score_i = \\frac{\\sum_u r_{ui} + k*\\mu}{n_i+k}$$\n",
    "\n",
    "where $r_ui$ is the rating on item i by user u, $n_i$ is the number of rating on item i, $\\mu$ is the global mean of ratings over all businesses and all users and k is the strength of the damping term.\n",
    "\n",
    "As the equation shows, the adjusted score uses the mechanism of the damped mean to regulate the extreme cases of having only a few extreme ratings. k controls the strength of the damping effect: the larger k is, the more actual ratings are required to overcome the global mean.\n",
    "\n",
    "In this case, k is set to 4 (which is the 10% quantile of the review counts for all businesses), but it can be tuned according to various business considerations.  \n",
    "\n",
    "Note:<br> \n",
    "Here, the age of the rating is not adjusted in the current version of the proposed metric. This is because 90% of the reviews/ratings are from year 2011 and later, and are considered quite relevant. Therefore, the need of adjusting for the age of the ratings is not strong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global mean rating is: 3.7277814701620127\n"
     ]
    }
   ],
   "source": [
    "# compute globe mean ratings of all businesses and all reviews\n",
    "globe_mean = ((business.stars * business.review_count).sum())/(business.review_count.sum())\n",
    "print(\"global mean rating is:\", globe_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10      4.0\n",
      "0.25      8.0\n",
      "0.50     22.0\n",
      "0.75     66.0\n",
      "0.90    172.0\n",
      "Name: review_count, dtype: float64\n",
      "\n",
      "rank by the adjusted score in descending order:\n",
      "       review_count  stars  adjusted_score\n",
      "7464           1746    5.0        4.984169\n",
      "31910          1380    5.0        4.980037\n",
      "45401           547    5.0        4.950811\n",
      "7784            520    5.0        4.948360\n",
      "28162           472    5.0        4.943342\n",
      "\n",
      "rank by the original score in descending order:\n",
      "       review_count  stars  adjusted_score\n",
      "22115             7    5.0        4.034869\n",
      "23114             5    5.0        3.963377\n",
      "42990             5    5.0        3.963377\n",
      "42989            16    5.0        4.263452\n",
      "12778             3    5.0        3.880448\n",
      "\n",
      "rank by the least number of reviews:\n",
      "       review_count  stars  adjusted_score\n",
      "0                 3    4.5        3.820448\n",
      "5707              3    4.0        3.760448\n",
      "16594             3    4.0        3.760448\n",
      "5699              3    3.5        3.700448\n",
      "16605             3    3.5        3.700448\n"
     ]
    }
   ],
   "source": [
    "print(business.review_count.quantile([0.1,0.25,0.5,0.75,0.9]))\n",
    "k = 22 # set strength k to 22, which is the 50% quantile of the review counts for all businesses\n",
    "business['adjusted_score'] = (business.review_count * business.stars + k * globe_mean)/(business.review_count + k)\n",
    "print(\"\\nrank by the adjusted score in descending order:\")\n",
    "print(business[['review_count','stars','adjusted_score']].sort_values('adjusted_score', ascending=False).head(5))\n",
    "print(\"\\nrank by the original score in descending order:\")\n",
    "print(business[['review_count','stars','adjusted_score']].sort_values('stars', ascending=False).head(5))\n",
    "print(\"\\nrank by the least number of reviews:\")\n",
    "print(business[['review_count','stars','adjusted_score']].sort_values('review_count', ascending=True).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create recommender class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 non-personalized keyword filtering module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data type of the 'postal_code' column of business dataframe to string type\n",
    "business['postal_code'] = business.postal_code.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    \n",
    "    def __init__(self, n=5, original_score=False):\n",
    "        \"\"\"initiate a Recommender object by passing the desired number of recommendations to make, the default number is 10.\n",
    "        By default, the adjusted score will be used for ranking; To rank by the original average rating of the restaurant, pass original_score=True\n",
    "        \"\"\"\n",
    "        self.n = n # number of recommendations to make, default is 5\n",
    "        self.original_score = original_score # boolean indicating whether the original average rating or the adjusted score is used\n",
    "        # initiate a list of column names to display in the recommendation results\n",
    "        self.column_to_display = ['state','city','name','address','attributes.RestaurantsPriceRange2','cuisine','style','review_count','stars','adjusted_score']\n",
    "        \n",
    "        # initiate the list of recommendations to be the entire catalog of the 'business' dataframe sorted by the score of interest\n",
    "        if self.original_score:  # set sorting criteria to the originial star rating\n",
    "            score = 'stars'\n",
    "        else:  # set sorting criteria to the adjusted score\n",
    "            score = 'adjusted_score'\n",
    "        self.recomm = business.sort_values(score, ascending=False)\n",
    "        \n",
    "    def _filter_by_location(self):\n",
    "        \"\"\"Filter and update the dataframe of recommendations by the matching location of interest.\n",
    "        A combination of state, city and zipcode is used as the location information, partially missing information can be handled. \n",
    "        Matching restaurant is defined as the restaurant within the acceptable distance (max_distance) of the location of interest.\n",
    "        note: this hidden method should only be called within the method 'keyword'\n",
    "        \"\"\"       \n",
    "        from geopy.geocoders import Nominatim\n",
    "        from geopy.exc import GeocoderTimedOut\n",
    "        geolocator = Nominatim(user_agent=\"yelp_recommender\") # use geopy.geocoders to make geolocation queries\n",
    "        address = [self.city, self.state, self.zipcode]\n",
    "        address = \",\".join([str(i) for i in address if i != None])\n",
    "        # use geolocate query to find the coordinate for the location of interest\n",
    "        try:\n",
    "            location = geolocator.geocode(address, timeout=10) \n",
    "        except GeocoderTimedOut as e:\n",
    "            print(\"Error: geocode failed to locate the address of interest {} with message {}\".format(address, e.message))            \n",
    "\n",
    "        # calculate the geodesic distance between each restaurant and the location of interest and add as a new column ''distance_to_interest'\n",
    "        self.recomm['distance_to_interest'] = self.recomm.apply(lambda row: great_circle_mile(row.latitude, row.longitude, location.latitude, location.longitude), axis=1)\n",
    "        # add the new column 'distance_to_interest' to the list of columns to display in the recommendation result\n",
    "        self.column_to_display.insert(0, 'distance_to_interest')\n",
    "        # filter by the desired distance\n",
    "        self.recomm = self.recomm[self.recomm.distance_to_interest <= self.max_distance]\n",
    "\n",
    "    def _filter_by_state(self):\n",
    "        \"\"\" Filter and update the dataframe of recommendations by the matching state.\n",
    "        note: this hidden method should only be called within the method 'keyword'\n",
    "        \"\"\"\n",
    "        self.recomm = self.recomm[self.recomm.state == self.state.upper()]\n",
    "    \n",
    "    def _filter_by_cuisine(self):\n",
    "        \"\"\" Filter and update the dataframe of recommendations by the matching cuisine of interest. \n",
    "        note: this hidden method should only be called within the method 'keyword'\n",
    "        \"\"\"                         \n",
    "        idx = []\n",
    "        for i in self.recomm.index: \n",
    "            if self.recomm.loc[i,'cuisine'] is not np.nan:\n",
    "                entries = self.recomm.loc[i,'cuisine'].split(',')\n",
    "                if self.cuisine in entries:\n",
    "                    idx.append(i)\n",
    "        self.recomm = self.recomm.loc[idx]\n",
    "    \n",
    "    def _filter_by_style(self):  \n",
    "        \"\"\" Filter and update the dataframe of recommendations by the matching style of interest. \n",
    "        note: this hidden method should only be called within the method 'keyword'\n",
    "        \"\"\"\n",
    "        idx = []\n",
    "        for i in self.recomm.index: \n",
    "            if self.recomm.loc[i,'style'] is not np.nan:\n",
    "                entries = self.recomm.loc[i,'style'].split(',')\n",
    "                if self.style in entries:\n",
    "                    idx.append(i)\n",
    "        self.recomm = self.recomm.loc[idx]\n",
    "    \n",
    "    def display_recommendation(self):\n",
    "        \"\"\" Display the list of top n recommended restaurants\n",
    "        \"\"\"\n",
    "        # limit the list of recommendation to only top n at max\n",
    "        if self.n < len(self.recomm):\n",
    "            self.recomm = self.recomm.iloc[:self.n]\n",
    "        if len(self.recomm) == 0:\n",
    "            print(\"Sorry, there is no matching recommendations.\")\n",
    "        else: \n",
    "            print(\"The top {} recommended restaurants matching your keywords are\".format(self.n))\n",
    "            print(self.recomm[self.column_to_display])\n",
    "    \n",
    "    # non-personalized keyword filtering-based recommendation module\n",
    "    def keyword(self, zipcode=None, city=None, state=None, max_distance=10, cuisine=None, style=None):\n",
    "        \"\"\"Non-personalized recommendation by keyword filtering: \n",
    "        Support filtering by the desired distance and location (zipcode, city, state) of interest, \n",
    "        by the desired cuisine of interest and by the desired style of interest.\n",
    "        Everytime this method is called, a new list of recommendation is created regardless of prior history.\n",
    "        ---\n",
    "        Note:\n",
    "        state: needs to be the upper case of the state abbreviation, e.g.: 'NV', 'CA'\n",
    "        max_distance: the max acceptable distance between the restaurant and the location of interest, unit is in miles, default is 10\n",
    "        ---\n",
    "        \"\"\"\n",
    "        # re-initiate the following variables every time the module is called so that the recommendation starts fresh\n",
    "        self.recomm = business # start with the entire 'business' catalog\n",
    "        self.recomm['distance_to_interest'] = np.nan # reset the distance between each restaurant and the location of interest\n",
    "        self.column_to_display = ['state','city','name','address','attributes.RestaurantsPriceRange2','cuisine','style','review_count','stars','adjusted_score'] # reset the columns to display\n",
    "        \n",
    "        # assign variables based on user's keyword inputs\n",
    "        self.zipcode = zipcode\n",
    "        self.city = city\n",
    "        self.state = state \n",
    "        self.max_distance = max_distance\n",
    "        self.cuisine = cuisine\n",
    "        self.style = style\n",
    "         \n",
    "        \n",
    "            \n",
    "        # filter by restaurant location\n",
    "        if (self.zipcode != None) or (self.city != None) or (self.state != None):      \n",
    "            if (self.zipcode != None) or (self.city != None): # use zipcode and/or city whenever available\n",
    "                self._filter_by_location()\n",
    "            else: # filter by state if state is the only location information available \n",
    "                self._filter_by_state()\n",
    "            if len(self.recomm) == 0:\n",
    "                print(\"no restaurant found for the matching location of interest.\")\n",
    "                return []\n",
    "        \n",
    "        # filter by restaurant 'cuisine'\n",
    "        if self.cuisine != None:\n",
    "            self._filter_by_cuisine()\n",
    "            if len(self.recomm) == 0:\n",
    "                print(\"no restaurant found for the matching cuisine of {}\".format(self.cuisine))\n",
    "                return []\n",
    "        \n",
    "        # filter by restaurant 'style'\n",
    "        if self.style != None:\n",
    "            self._filter_by_style() \n",
    "            if len(self.recomm) == 0:\n",
    "                print(\"no restaurant found for the matching style of {}\".format(self.style))\n",
    "                return []\n",
    "        \n",
    "        # sort the matching list of restaurants by the score of interest\n",
    "        if self.original_score:  # set sorting criteria to the originial star rating\n",
    "            score = 'stars'\n",
    "        else:  # set sorting criteria to the adjusted score\n",
    "            score = 'adjusted_score'\n",
    "        self.recomm = self.recomm.sort_values(score, ascending=False)\n",
    "        \n",
    "        # display the list of top n recommendations\n",
    "        self.display_recommendation()\n",
    "        \n",
    "        return self.recomm\n",
    "    \n",
    "    # personalized content-based filtering recommender module\n",
    "    def content(self, user_id=None):\n",
    "        \"\"\"Passing of user_id is required if personalized recommendation is desired.\n",
    "        \"\"\"\n",
    "        self.recomm = business # start with the entire 'business' catalog every time the module is called\n",
    "                           \n",
    "        self.user_id = user_id  # user_id for personalized recommendation using content_based filtering \n",
    "                          \n",
    "        if self.user_id is None:\n",
    "            print(\"no user_id is provided\")\n",
    "        if self.user_id not in user.user_id:\n",
    "            print(\"No data available for this user_id\")\n",
    "        \n",
    "        # to be added\n",
    "        \n",
    "        # display the list of recommendations\n",
    "        self.display_recommendation()\n",
    "    \n",
    "    # personalized collaborative-based filtering recommender module\n",
    "    def collaborative(self, user_id=None):\n",
    "        \"\"\"Passing of user_id is required if personalized recommendation is desired.\n",
    "        \"\"\"\n",
    "        self.recomm = business # start with the entire 'business' catalog every time the module is called\n",
    "                           \n",
    "        self.user_id = user_id # user_id for personalized recommendation using collaborative filtering \n",
    "\n",
    "        if self.user_id is None:\n",
    "            print(\"no user_id is provided\")\n",
    "        if self.user_id not in user.user_id:\n",
    "            print(\"No data available for this user_id\")\n",
    "            \n",
    "        # to be added\n",
    "        \n",
    "        # display the list of recommendations\n",
    "        self.display_recommendation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the non-personalized keyword filtering module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "result from test0 (display only): \n",
      "The top 3 recommended restaurants matching your keywords are\n",
      "      state       city             name                       address  \\\n",
      "7464     AZ    Phoenix  Little Miss BBQ          4301 E University Dr   \n",
      "31910    NV  Las Vegas     Brew Tea Bar  7380 S Rainbow Blvd, Ste 101   \n",
      "45401    NV  Las Vegas       Gelatology  7910 S Rainbow Blvd, Ste 110   \n",
      "\n",
      "       attributes.RestaurantsPriceRange2                              cuisine  \\\n",
      "7464                                 2.0                             barbeque   \n",
      "31910                                1.0                 desserts, bubble tea   \n",
      "45401                                1.0  ice cream & frozen yogurt, desserts   \n",
      "\n",
      "                    style  review_count  stars  adjusted_score  \n",
      "7464          restaurants          1746    5.0        4.984169  \n",
      "31910  cafes, restaurants          1380    5.0        4.980037  \n",
      "45401                 NaN           547    5.0        4.950811  \n",
      "------\n",
      "result from test1 (no keywords): \n",
      "The top 3 recommended restaurants matching your keywords are\n",
      "      state       city             name                       address  \\\n",
      "7464     AZ    Phoenix  Little Miss BBQ          4301 E University Dr   \n",
      "31910    NV  Las Vegas     Brew Tea Bar  7380 S Rainbow Blvd, Ste 101   \n",
      "45401    NV  Las Vegas       Gelatology  7910 S Rainbow Blvd, Ste 110   \n",
      "\n",
      "       attributes.RestaurantsPriceRange2                              cuisine  \\\n",
      "7464                                 2.0                             barbeque   \n",
      "31910                                1.0                 desserts, bubble tea   \n",
      "45401                                1.0  ice cream & frozen yogurt, desserts   \n",
      "\n",
      "                    style  review_count  stars  adjusted_score  \n",
      "7464          restaurants          1746    5.0        4.984169  \n",
      "31910  cafes, restaurants          1380    5.0        4.980037  \n",
      "45401                 NaN           547    5.0        4.950811  \n",
      "------\n",
      "result from test2 (a combination of city and state): \n",
      "The top 3 recommended restaurants matching your keywords are\n",
      "       distance_to_interest state        city              name  \\\n",
      "7464               5.399251    AZ     Phoenix   Little Miss BBQ   \n",
      "13261              9.519138    AZ  Scottsdale  Simon's Hot Dogs   \n",
      "16103              1.038229    AZ     Phoenix  Tres Leches Cafe   \n",
      "\n",
      "                             address  attributes.RestaurantsPriceRange2  \\\n",
      "7464            4301 E University Dr                                2.0   \n",
      "13261  4280 Drinkwater Blvd, Ste 200                                1.0   \n",
      "16103            1330 W Roosevelt St                                1.0   \n",
      "\n",
      "                                           cuisine                   style  \\\n",
      "7464                                      barbeque             restaurants   \n",
      "13261  hot dogs, latin american, vegetarian, vegan             restaurants   \n",
      "16103                                 coffee & tea  juice bars & smoothies   \n",
      "\n",
      "       review_count  stars  adjusted_score  \n",
      "7464           1746    5.0        4.984169  \n",
      "13261           295    5.0        4.911707  \n",
      "16103           263    5.0        4.901794  \n",
      "------\n",
      "result from test3 (a combination of cuisine and style): \n",
      "The top 3 recommended restaurants matching your keywords are\n",
      "      state       city             name               address  \\\n",
      "7464     AZ    Phoenix  Little Miss BBQ  4301 E University Dr   \n",
      "14471    NV  Las Vegas   Poppa Naps BBQ                   NaN   \n",
      "39151    AZ    Phoenix    JL Smokehouse       1712 E Broadway   \n",
      "\n",
      "       attributes.RestaurantsPriceRange2  \\\n",
      "7464                                 2.0   \n",
      "14471                                2.0   \n",
      "39151                                2.0   \n",
      "\n",
      "                                            cuisine  \\\n",
      "7464                                       barbeque   \n",
      "14471            barbeque, hot dogs, american (new)   \n",
      "39151  barbeque, sandwiches, american (traditional)   \n",
      "\n",
      "                                    style  review_count  stars  adjusted_score  \n",
      "7464                          restaurants          1746    5.0        4.984169  \n",
      "14471  restaurants, caterers, food stands           122    5.0        4.805633  \n",
      "39151                         restaurants            56    5.0        4.641169  \n",
      "------\n",
      "result from test4 (a combination of state, cuisine and style): \n",
      "The top 3 recommended restaurants matching your keywords are\n",
      "      state       city                                       name  \\\n",
      "19142    NV  Las Vegas  Aroma Cuisine of the World/Oscar Catering   \n",
      "33535    NV  Las Vegas                                       Raku   \n",
      "26169    NV  Las Vegas                      Yojié Japanese Fondue   \n",
      "\n",
      "                              address  attributes.RestaurantsPriceRange2  \\\n",
      "19142      6370 W Flamingo Rd, Ste 30                                2.0   \n",
      "33535  5030 Spring Mountain Rd, Ste 2                                3.0   \n",
      "26169      9440 W Sahara Ave, Ste 175                                2.0   \n",
      "\n",
      "                                                cuisine  \\\n",
      "19142            desserts, italian, mexican, sandwiches   \n",
      "33535                       desserts, japanese, seafood   \n",
      "26169  desserts, specialty food, japanese, asian fusion   \n",
      "\n",
      "                                     style  review_count  stars  \\\n",
      "19142  restaurants, juice bars & smoothies            35    5.0   \n",
      "33535                          restaurants          1400    4.5   \n",
      "26169                          restaurants           391    4.5   \n",
      "\n",
      "       adjusted_score  \n",
      "19142        4.508968  \n",
      "33535        4.488053  \n",
      "26169        4.458865  \n",
      "------\n",
      "result from test5 (no matching location): \n",
      "no restaurant found for the matching location of interest.\n",
      "------\n",
      "result from test6 (no matching cuisine): \n",
      "no restaurant found for the matching cuisine of abc\n",
      "------\n",
      "result from test7 (no matching style): \n",
      "no restaurant found for the matching style of abc\n",
      "------\n",
      "result from test8 (a combination of location, cuisine and style): \n",
      "The top 3 recommended restaurants matching your keywords are\n",
      "       distance_to_interest state     city                   name  \\\n",
      "9236               4.550027    AZ  Phoenix                Bobby Q   \n",
      "23589              9.583306    AZ  Phoenix        Reathrey Sekong   \n",
      "25730              7.104974    AZ  Phoenix  Papa Joe's Fish-N-Que   \n",
      "\n",
      "                       address  attributes.RestaurantsPriceRange2  \\\n",
      "9236           8501 N 27th Ave                                2.0   \n",
      "23589  1312 E Indian School Rd                                2.0   \n",
      "25730   2019 W Bethany Home Rd                                1.0   \n",
      "\n",
      "                        cuisine                  style  review_count  stars  \\\n",
      "9236   barbeque, american (new)  restaurants, caterers          2267    4.5   \n",
      "23589                  barbeque            restaurants           440    4.5   \n",
      "25730                  barbeque            restaurants           222    4.5   \n",
      "\n",
      "       adjusted_score  \n",
      "9236         4.492578  \n",
      "23589        4.463228  \n",
      "25730        4.430374  \n",
      "------\n",
      "result from test9 (top 10 recommendations ranked by original average rating): \n",
      "The top 10 recommended restaurants matching your keywords are\n",
      "       distance_to_interest state      city                     name  \\\n",
      "23114              2.944534    AZ  Glendale             Tha Spot BBQ   \n",
      "44933              1.077608    AZ   Phoenix  Pork on a Fork Catering   \n",
      "13651              2.566000    AZ   Phoenix       Big Cuz's Catering   \n",
      "25730              7.104974    AZ   Phoenix    Papa Joe's Fish-N-Que   \n",
      "9236               4.550027    AZ   Phoenix                  Bobby Q   \n",
      "23589              9.583306    AZ   Phoenix          Reathrey Sekong   \n",
      "2029               2.297742    AZ   Phoenix                  Grady's   \n",
      "36705              5.676696    AZ   Phoenix   Smokehouse Bar & Grill   \n",
      "18269              9.441714    AZ   Phoenix             Town Talk II   \n",
      "36040              8.163429    AZ   Phoenix        Circle H Barbecue   \n",
      "\n",
      "                             address  attributes.RestaurantsPriceRange2  \\\n",
      "23114          4356 W Thunderbird Rd                                1.0   \n",
      "44933                 1732 W Bell Rd                                NaN   \n",
      "13651  428 E Thunderbird Rd, Ste 424                                NaN   \n",
      "25730         2019 W Bethany Home Rd                                1.0   \n",
      "9236                 8501 N 27th Ave                                2.0   \n",
      "23589        1312 E Indian School Rd                                2.0   \n",
      "2029                11801 N 19th Ave                                1.0   \n",
      "36705               3128 E Cactus Rd                                1.0   \n",
      "18269                3509 N 19th Ave                                1.0   \n",
      "36040             730 W Camelback Rd                                2.0   \n",
      "\n",
      "                        cuisine                               style  \\\n",
      "23114                  barbeque                         restaurants   \n",
      "44933                  barbeque               restaurants, caterers   \n",
      "13651                  barbeque  restaurants, food trucks, caterers   \n",
      "25730                  barbeque                         restaurants   \n",
      "9236   barbeque, american (new)               restaurants, caterers   \n",
      "23589                  barbeque                         restaurants   \n",
      "2029                   barbeque                         restaurants   \n",
      "36705         barbeque, tex-mex     restaurants, breakfast & brunch   \n",
      "18269                  barbeque                         restaurants   \n",
      "36040                  barbeque                         restaurants   \n",
      "\n",
      "       review_count  stars  adjusted_score  \n",
      "23114             5    5.0        3.963377  \n",
      "44933            12    5.0        4.176800  \n",
      "13651             5    5.0        3.963377  \n",
      "25730           222    4.5        4.430374  \n",
      "9236           2267    4.5        4.492578  \n",
      "23589           440    4.5        4.463228  \n",
      "2029             19    4.5        4.085639  \n",
      "36705            46    4.0        3.911929  \n",
      "18269            78    4.0        3.940112  \n",
      "36040            63    4.0        3.929543  \n",
      "CPU times: user 8.06 s, sys: 192 ms, total: 8.25 s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# initiate a Recommender object\n",
    "kw = Recommender(n=3)\n",
    "\n",
    "# test0: display only (same as no keywords)\n",
    "print(\"------\\nresult from test0 (display only): \")\n",
    "kw.display_recommendation()\n",
    "\n",
    "# test1: no keywords\n",
    "print(\"------\\nresult from test1 (no keywords): \")\n",
    "kw.keyword();\n",
    "\n",
    "# test 2: a combination of city, state and zipcode\n",
    "print(\"------\\nresult from test2 (a combination of city and state): \")\n",
    "kw.keyword(city='Phoenix', state='AZ', zipcode='85023');\n",
    "\n",
    "# test 3: a combination of cuisine and style\n",
    "print(\"------\\nresult from test3 (a combination of cuisine and style): \")\n",
    "kw.keyword(cuisine='barbeque', style='restaurants');\n",
    "\n",
    "# test 4: a combination of state, cuisine and style\n",
    "print(\"------\\nresult from test4 (a combination of state, cuisine and style): \")\n",
    "kw.keyword(state='NV', cuisine='desserts', style='restaurants');\n",
    "\n",
    "# test 5: no matching location\n",
    "print(\"------\\nresult from test5 (no matching location): \")\n",
    "kw.keyword(city='milpitas', zipcode='95035');\n",
    "\n",
    "# test 6: no matching 'cuisine'\n",
    "print(\"------\\nresult from test6 (no matching cuisine): \")\n",
    "kw.keyword(cuisine='abc');\n",
    "\n",
    "# test 7: no matching 'style'\n",
    "print(\"------\\nresult from test7 (no matching style): \")\n",
    "kw.keyword(style='abc');\n",
    "\n",
    "# test 8: a combination of location, cuisine and style\n",
    "print(\"------\\nresult from test8 (a combination of location, cuisine and style): \")\n",
    "kw.keyword(city='Phoenix', zipcode='85023',cuisine='barbeque', style='restaurants');\n",
    "\n",
    "# test 9: use the original average rating and return top 10 recommendations\n",
    "print(\"------\\nresult from test9 (top 10 recommendations ranked by original average rating): \")\n",
    "kw2 = Recommender(n=10, original_score=True)\n",
    "kw2.keyword(city='Phoenix', zipcode='85023',cuisine='barbeque', style='restaurants');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, 9 tests (9 queries) are performed with a total CPU time of 8 seconds and elapsed time of 12 seconds. This averages to roughly 1 second per queries which is very reasonable in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 collaborative filtering module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5996995 entries, 0 to 5996994\n",
      "Data columns (total 9 columns):\n",
      "funny          int64\n",
      "stars          int64\n",
      "useful         int64\n",
      "cool           int64\n",
      "text           object\n",
      "business_id    object\n",
      "user_id        object\n",
      "review_id      object\n",
      "date           object\n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 411.8+ MB\n"
     ]
    }
   ],
   "source": [
    "review.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using pandas pivot to convert 'review' dataframe to the 'user_id' x 'business_id' matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying only with the first 50,000 rows\n",
    "matrix_reduced = review[:50000].pivot(index='user_id', columns='business_id', values='stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20076, 30915)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20076 entries, ---PLwSf5gKdIoVnyRHgBA to zzq0TgPc5-b3-7XKt6fwJA\n",
      "Columns: 30915 entries, --6MefnULPED_I942VcFNA to zzwhN7x37nyjP0ZM8oiHmw\n",
      "dtypes: float64(30915)\n",
      "memory usage: 4.6+ GB\n",
      "None\n",
      "1518168\n",
      "188593\n",
      "The non-NaN entries in the target matrix is 0.002094538196300487%\n"
     ]
    }
   ],
   "source": [
    "print(matrix_reduced.shape)\n",
    "print(matrix_reduced.info())\n",
    "\n",
    "# check the target matrix dimension\n",
    "print(len(review.user_id.value_counts()))\n",
    "print(len(review.business_id.value_counts()))\n",
    "\n",
    "# check sparsity\n",
    "print(\"The non-NaN entries in the target matrix is {}%\".format(len(review)*100/(len(review.user_id.value_counts())*len(review.business_id.value_counts()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, the matrix_reduced created by only pivoting the first 50,000 rows is already taking 4.6+ GB, and the matrix_reduced shape is 20076 x 30915.<br>\n",
    "The actual matrix shape will be len(review.user_id.value_counts()) x len(review.business_id.value_counts()), that is 1518168 x 188593, 461 times larger. Therefore, it's impossible given the space (memory) constrain. <br>\n",
    "\n",
    "Alternatively, the target matrix is very sparse, therefore to make it work with the memory constrain, the 'stars' rating in the 'review' dataframe needs to be pivoted into a sparse matrix directly, by 'user_id' and 'business_id'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pivot directly into a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method for pivoting dataframe into a sparse matrix directly\n",
    "# version: python 3.6.5, pandas 0.23.3, numpy 1.15.0 scipy 1.1.0\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# return the resulting sparse matrix only\n",
    "def df_pivot_sparse_matrix_simple(df, idx, col, val):\n",
    "    \"\"\"pivot a pandas dataframe into sparse matrix directly using scipy.sparse.csr_matrix and return the resulting sparse matrix. \n",
    "    necessary when the df is large and pandas pivot (dense matrix) doesn't work due to space (memory) constrain. \n",
    "    ---\n",
    "    input\n",
    "    df: the pandas dataframe of interest\n",
    "    idx: the column name of the df to be used as the index in the sparse matrix;\n",
    "    col: the column name of the df to be used as the column in the sparse matrix;\n",
    "    val: the column name of the df to be used as the actual value in the sparse matrix;\n",
    "    \"\"\"\n",
    "    x = df[idx].astype(CategoricalDtype(ordered=True)).cat.codes\n",
    "    y = df[col].astype(CategoricalDtype(ordered=True)).cat.codes\n",
    "    return csr_matrix((df[val].values, (x, y)), shape=(df[idx].nunique(), df[col].nunique()))\n",
    "\n",
    "\n",
    "# return the resulting sparse matrix along with the mapping dictionaries of matrix indices to the orignial values in the corresponding columns of df\n",
    "def df_pivot_sparse_matrix(df, idx, col, val):\n",
    "    \"\"\"pivot a pandas dataframe into sparse matrix directly using scipy.sparse.csr_matrix and return the resulting sparse matrix, \n",
    "    necessary when the df is large and pandas pivot (dense matrix) doesn't work due to space (memory) constrain. \n",
    "    ---\n",
    "    input\n",
    "    df: the pandas dataframe of interest\n",
    "    idx: the column name of the df to be used as the index in the sparse matrix;\n",
    "    col: the column name of the df to be used as the column in the sparse matrix;\n",
    "    val: the column name of the df to be used as the actual value in the sparse matrix;\n",
    "    ---\n",
    "    return:\n",
    "    sparse_matrix: the resulting sparse matrix\n",
    "    map_idx: the dictionary to map the numerical row indices of the sparse matrix back to the unique values in the idx column of the original df\n",
    "    map_col: the dictionary to map the numerical column indices of the sparse matrix back to the uniqe values in the col column of the original df\n",
    "    \"\"\"\n",
    "    idx_c = CategoricalDtype(sorted(df[idx].unique()),ordered=True) # find unique values in the idx column and define as a categorical type\n",
    "    col_c = CategoricalDtype(sorted(df[col].unique()),ordered=True) # find unique values in the col column and define as a categorical type\n",
    "\n",
    "    x = df[idx].astype(idx_c).cat.codes # cast columns to the newly created categorical type and access the underlying integer codes (corresponding numbering of the categories)\n",
    "    y = df[col].astype(col_c).cat.codes \n",
    "    sparse_matrix = csr_matrix((df[val].values, (x, y)), \\\n",
    "                           shape=(len(idx_c.categories), len(col_c.categories))) # map to the sparse matrix\n",
    "    \n",
    "    map_idx = dict(zip(np.arange(len(idx_c.categories)), list(idx_c.categories))) # create the mapping dictionaries\n",
    "    map_col = dict(zip(np.arange(len(col_c.categories)), list(col_c.categories)))\n",
    "                               \n",
    "    return sparse_matrix, map_idx, map_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.27 s, sys: 1 s, total: 9.27 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# convert to sparse matrix\n",
    "matrix, map_user_id, map_business_id = df_pivot_sparse_matrix(review, 'user_id', 'business_id', 'stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix shape: (1518168, 188593)\n",
      "memory use: 9.7545725 Mb\n",
      "int64\n",
      "5    2641880\n",
      "4    1335957\n",
      "1     858139\n",
      "3     673206\n",
      "2     487813\n",
      "Name: stars, dtype: int64\n",
      "5996992\n",
      "5996995\n"
     ]
    }
   ],
   "source": [
    "# inspect the sparse matrix\n",
    "\n",
    "# check shape\n",
    "print(\"matrix shape:\", matrix.shape)\n",
    "\n",
    "# check memory use\n",
    "print(\"memory use: {} Mb\".format((matrix.data.nbytes + matrix.indptr.nbytes + matrix.indices.nbytes)*0.125*1e-6))\n",
    "\n",
    "# check data type\n",
    "print(matrix.dtype)\n",
    "print(review.stars.value_counts())\n",
    "\n",
    "# check non-NaN values\n",
    "print(len(matrix.data))\n",
    "print(review.stars.notnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '---1lKK3aKOuomHnwAkAow'), (1, '---89pEy_h9PvHwcHNbpyg'), (2, '---94vtJ_5o_nikEs6hUjg'), (3, '---PLwSf5gKdIoVnyRHgBA'), (4, '---cu1hq55BP9DWVXXKHZg')]\n",
      "[(0, '--1UhMGODdWsrMastO9DZw'), (1, '--6MefnULPED_I942VcFNA'), (2, '--7zmmkVg-IMGaXbuVd0SQ'), (3, '--8LPVSo5i0Oo61X01sV9A'), (4, '--9QQLMTbFzLJ_oT-ON3Xw')]\n"
     ]
    }
   ],
   "source": [
    "# inspect the mapping dictionaries\n",
    "print(list(map_user_id.items())[:5])\n",
    "print(list(map_business_id.items())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Q]: ??? why non-NaN values are not consistent (missing 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matrix factorization using scikit-learn non-negative matrix factorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute performance\n",
    "\n",
    "def get_performance(m_pred_H, m_pred_W, m_true):\n",
    "    \"\"\" compute the RMSE(root mean squared error) between \n",
    "    m_true is a sparse matrix, use m_true.data, m_true.indices, and m_true.indptr to compute its non\n",
    "    \"\"\"\n",
    "    # to be added\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1518168, 10)\n",
      "(10, 188593)\n"
     ]
    }
   ],
   "source": [
    "# selecting n_components, set to 10 first, later use cross validation to optimize\n",
    "\n",
    "model = NMF(n_components=10, init='random', random_state=0)\n",
    "W = model.fit_transform(matrix)\n",
    "H = model.components_\n",
    "\n",
    "print(W.shape)\n",
    "print(H.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems to be solved\n",
    "A) train_test_split on sparse matrix, randomly split on (user_id, business_id) combination. \n",
    "problem: some users only have one rating of one restaurant, those need to be in the training set. \n",
    "B) evaluate the test matrix only on available ratings (write def get_performance())\n",
    "C) optimize n_components via cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try out scikit-surprise package to handle the above complications\n",
    "http://surpriselib.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise import NMF, SVD\n",
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.6 s, sys: 29.2 s, total: 1min 1s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prepare the data\n",
    "\n",
    "# create a Reader object with the rating_scale from 1 to 5\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings in the exact order\n",
    "data = Dataset.load_from_df(review[['user_id', 'business_id', 'stars']], reader)\n",
    "\n",
    "# sample random trainset and testset\n",
    "trainset, testset = train_test_split(data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250368"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.n_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this method doesn't include all users either. But it will return trainset.global_mean if the user_id or the business_id to be predicted is not found in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4656\n",
      "CPU times: user 7min 31s, sys: 44.1 s, total: 8min 16s\n",
      "Wall time: 8min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NMF with defaults\n",
    "\n",
    "nmf = NMF() # initiate a NMF algorithm object\n",
    "nmf.fit(trainset) # training\n",
    "pred_nmf = nmf.test(testset) # predict ratings for the testset\n",
    "accuracy.rmse(pred_nmf) # compute RMSE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.2825\n",
      "CPU times: user 5min 29s, sys: 38.6 s, total: 6min 8s\n",
      "Wall time: 6min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SVD with defaults\n",
    "\n",
    "svd = SVD() # initiate a SVD algorithm object\n",
    "svd.fit(trainset) # training\n",
    "pred_svd = svd.test(testset) # predict ratings for the testset\n",
    "accuracy.rmse(pred_svd) # compute RMSE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross validation to optimize parameters of NMF\n",
    "param_grid = {'n_factors': [10,20], 'n_epochs': [20, 50]}\n",
    "gs = GridSearchCV(nmf, param_grid, measures='rmse', cv=3)\n",
    "gs.fit(train)\n",
    "# best RMSE score\n",
    "print(gs.best_score)\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross validation to optimize parameters of SVD\n",
    "param_grid = {'n_factors': [10,50], 'n_epochs': [10, 20], 'lr_all': [0.002, 0.01],'reg_all': [0.02, 0.1]}\n",
    "gs = GridSearchCV(svd, param_grid, measures='rmse', cv=3)\n",
    "gs.fit(train)\n",
    "# best RMSE score\n",
    "print(gs.best_score)\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to control API interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business dataset joins review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# busi_review = pd.merge(business[['business_id','stars','review_count']], review[['business_id','review_id','stars']], how='left', on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compare the consistency of review counts from business dataset vs review dataset\n",
    "# compare_review = busi_review.groupby('business_id')[['business_id','review_count']].agg({'business_id':'count','review_count':'mean'})\n",
    "# print(compare_review.head())\n",
    "# print(len(compare_review))\n",
    "# print(compare_review[compare_review.business_id != compare_review.review_count].head())\n",
    "# print(len(compare_review[compare_review.business_id != compare_review.review_count]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # compare the consistency of average rating from business dataset vs review dataset\n",
    "# compare_rating = busi_review.groupby('business_id')[['stars_x','stars_y']].mean()\n",
    "# compare_rating['stars_y_round'] = (compare_rating.stars_y//0.5)*0.5 + ((compare_rating.stars_y % 0.5)//0.25)*0.5\n",
    "# print(compare_rating.head())\n",
    "# print(len(compare_rating))\n",
    "# print(compare_rating[compare_rating.stars_x != compare_rating.stars_y_round].head())\n",
    "# print(len(compare_rating[compare_rating.stars_x != compare_rating.stars_y_round]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
